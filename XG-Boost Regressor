#Importing Libraries

import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
conda install -c anaconda py-xgboost
from xgboost.sklearn import XGBRegressor
import xgboost
from sklearn.model_selection import GridSearchCV
from sklearn import metrics

food=pd.read_excel("C://Users/Tejasri/Desktop/Data_Train.xlsx")
foodtest=pd.read_excel("C://Users/Tejasri/Desktop/Data_Test.xlsx")
scaler = MinMaxScaler()
#(feature_range = (0,1))
food[["COST"]] = scaler.fit_transform(food[["COST"]])
scaler.inverse_transform(food[['COST']])
t=food[food.loc[:, food.columns == 'COST'].columns]
x=food
x.head()
x.drop(x.columns[[8]],axis=1,inplace=True)
train_objs_num = len(x)
dataset=pd.concat(objs=[x,foodtest],axis=0)

title=dataset["TITLE"].str.split(",",n=1,expand=True)
dataset["Title1"]=title[0]
dataset.head()

title=foodtest["TITLE"].str.split(",",n=1,expand=True)
foodtest["Title1"]=title[0]

pd.get_dummies(dataset["Title1"])
dataset=pd.concat([dataset,pd.get_dummies(dataset["Title1"])],axis=1)

pd.get_dummies(foodtest["Title1"])
foodtest=pd.concat([foodtest,pd.get_dummies(foodtest["Title1"])],axis=1)

dataset["VOTES"]=dataset["VOTES"].str.strip("votes")

foodtest["VOTES"]=foodtest["VOTES"].str.strip("votes")

dataset["VOTES"]=dataset["VOTES"].str.strip()

foodtest["VOTES"]=foodtest["VOTES"].str.strip()

dataset["VOTES"]=dataset.VOTES.astype(float)
dataset["VOTES"].isnull().sum()
foodtest["VOTES"]=foodtest.VOTES.astype(float)
foodtest["VOTES"].isnull().sum()

dataset['VOTES'] = dataset['VOTES'].fillna(0)

foodtest["VOTES"]=foodtest["VOTES"].fillna(0)

round(dataset["VOTES"].mean())
round(foodtest["VOTES"].mean())

dataset["VOTES"]=dataset["VOTES"].replace(0,379)

foodtest["VOTES"]=foodtest["VOTES"].replace(0,389)

dataset['RATING'] = dataset["RATING"].replace("-","0")
dataset['RATING'] = dataset["RATING"].replace("NEW","0")
dataset["RATING"]=dataset["RATING"].astype(float)

foodtest["RATING"]=foodtest["RATING"].replace("-","0")
foodtest["RATING"]=foodtest["RATING"].replace("NEW","0")
foodtest["RATING"]=foodtest["RATING"].astype(float)

dataset["RATING"].mean()
foodtest["RATING"].mean()

dataset["RATING"]=dataset["RATING"].replace(0,3.783377)

foodtest["RATING"]=foodtest["RATING"].replace(0,3.7806)

dataset['Happiness'] = dataset['RATING'] * dataset['VOTES']

foodtest["Happiness"]=foodtest["RATING"]*foodtest["VOTES"]

dataset['Happiness'] = dataset['Happiness'].astype(float)
dataset["Happiness"].dropna(inplace=True)

foodtest["Happiness"]=foodtest["Happiness"].astype(float)
foodtest["Happiness"].dropna(inplace=True)

scaler = MinMaxScaler()
dataset[["Happiness"]] = scaler.fit_transform(dataset[["Happiness"]])

foodtest[["Happiness"]]=scaler.fit_transform(foodtest[["Happiness"]])

midnight=list(dataset["TIME"])
for i in range(len(midnight)):
    if "night" in midnight[i]:
        midnight[i]=1
    elif "night" not in midnight[i]:
        midnight[i]=0
dataset["Midnight"]=midnight

midnight=list(foodtest["TIME"])
for i in range(len(midnight)):
    if "night" in midnight[i]:
        midnight[i]=1
    elif "night" not in midnight[i]:
        midnight[i]=0
foodtest["Midnight"]=midnight

Alldays=list(dataset["TIME"])
for i in range(len(Alldays)):
    if "(Mon-Sun)" in Alldays[i]:
        Alldays[i]=1
    elif "(Mon-Sum)" not in Alldays[i]:
        Alldays[i]=0
dataset["Alldays"]=Alldays

Alldays=list(foodtest["TIME"])
for i in range(len(Alldays)):
    if "(Mon-Sun)" in Alldays[i]:
        Alldays[i]=1
    elif "(Mon-Sum)" not in Alldays[i]:
        Alldays[i]=0
foodtest["Alldays"]=Alldays

scaler = MinMaxScaler()
dataset[["RATING"]] = scaler.fit_transform(dataset[["RATING"]])

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
foodtest[["RATING"]] = scaler.fit_transform(foodtest[["RATING"]])

ONEAM=list(dataset["TIME"])
for i in range(len(ONEAM)):
    if "– 1am" in ONEAM[i]:
        ONEAM[i]=1
    elif "– 1am" not in ONEAM[i]:
        ONEAM[i]=0
dataset["ONEAM"]=ONEAM

ONEAM=list(foodtest["TIME"])
for i in range(len(ONEAM)):
    if "– 1am" in ONEAM[i]:
        ONEAM[i]=1
    elif "– 1am" not in ONEAM[i]:
        ONEAM[i]=0
foodtest["ONEAM"]=ONEAM

dataset["CITY"].replace(["Andheri Lokhandwala","Chembur.","Bandra West","Andheri West","Mulund East","Dombivali East","Mumbai This is a Delivery & Take-away Restaurant only.","Khar Mumbai","Mulund west","Mumbai Andheri East","Khar (west)","Khar (west)","Navi Mumbai.","Jogeshwari (w) Mumbai","Mumbai Andheri East","Malad East","khar west","Mumbai - 400013","West Mumbai","Lower Parel","East Mumbai","Andheri Lokhandwala.","Maharashtra","Powai","Mumbai."],"Mumbai",inplace=True)

foodtest["CITY"].replace(["Andheri Lokhandwala","Chembur.","Bandra West","Andheri West","Mulund East","Dombivali East","Mumbai This is a Delivery & Take-away Restaurant only.","Khar Mumbai","Mulund west","Mumbai Andheri East","Khar (west)","Khar (west)","Navi Mumbai.","Jogeshwari (w) Mumbai","Mumbai Andheri East","Malad East","khar west","Mumbai - 400013","West Mumbai","Lower Parel","East Mumbai","Andheri Lokhandwala.","Maharashtra","Powai","Mumbai."],"Mumbai",inplace=True)

dataset["CITY"].replace(["682036","Edappally","Kadavanthra","Ernakulam Circle kochi","Near Reliance Fresh","Kakkanad","Kochi Elamkulam","Ponnuruni Kochi","Kochi Vyttila","Kochi Palarivattom","682035.","kochi","Kochi Chullickal","kochi","aluva circle","Kerala 682001 India","Kerala 683585","Kochi.","Aluva","Kochi-16","Ernakulam","p.o Kochi","Kerala"],"Kochi",inplace=True)

foodtest["CITY"].replace(["682036","Edappally","Kadavanthra","Ernakulam Circle kochi","Near Reliance Fresh","Kakkanad","Kochi Elamkulam","Ponnuruni Kochi","Kochi Vyttila","Kochi Palarivattom","682035.","kochi","Kochi Chullickal","kochi","aluva circle","Kerala 682001 India","Kerala 683585","Kochi.","Aluva","Kochi-16","Ernakulam","p.o Kochi","Kerala"],"Kochi",inplace=True)

dataset["CITY"].replace(["India","Telegana Land Line:040-48507016","Telengana","Gachibowli","Mahdipatnam","Metro Pillar No21. Mettuguda main road near railway degree college.","hyderabad","Madhapur","Telangana","Near Santosh Banjara Hyderabad","Hyderabad.","Uppal","Attapur.","Khairatabad","Telagana Land Line:040-48507016","Begumpet Hyderabad","Jubilee Hills","Gachibowli Hyderabad","West Maredpally","Hitech City","Telangana 500081","Telangana 500070","Serilingampally","Hyderabad neerus emporium.","Metro Pillar No 21. Mettuguda main road near railway degree college."],"Hyderabad",inplace=True)

foodtest["CITY"].replace(["India","Telegana Land Line:040-48507016","Telengana","Gachibowli","Mahdipatnam","Metro Pillar No21. Mettuguda main road near railway degree college.","hyderabad","Madhapur","Telangana","Near Santosh Banjara Hyderabad","Hyderabad.","Uppal","Attapur.","Khairatabad","Telagana Land Line:040-48507016","Begumpet Hyderabad","Jubilee Hills","Gachibowli Hyderabad","West Maredpally","Hitech City","Telangana 500081","Telangana 500070","Serilingampally","Hyderabad neerus emporium.","Metro Pillar No 21. Mettuguda main road near railway degree college."],"Hyderabad",inplace=True)

dataset["CITY"].replace(["Bangalor","Bangalore-560066","5th Main Teachers Colony Kormangala Block 1 Bangalore 560034","Adjacent to Commercial Street","BTM Layout","Bangalore land mark above mahaveer hard ware","bangalore : 560085","bangalore : 560085","Kanakapura Road Banglore","5th Main Teachers Colony Koramangala Block 1 Bangalore 560034","Bangalore - 560076","Karnataka 560037","CPR layout harlur main road opposite to ozone ever green apartment Bangalore -","Karnataka 560103","Off Brigade Road","Bangalore - 560103","Ulsoo","Bengalore","Bengaluru"],"Bangalore",inplace=True)

foodtest["CITY"].replace(["Bangalor","Bangalore-560066","5th Main Teachers Colony Kormangala Block 1 Bangalore 560034","Adjacent to Commercial Street","BTM Layout","Bangalore land mark above mahaveer hard ware","bangalore : 560085","bangalore : 560085","Kanakapura Road Banglore","5th Main Teachers Colony Koramangala Block 1 Bangalore 560034","Bangalore - 560076","Karnataka 560037","CPR layout harlur main road opposite to ozone ever green apartment Bangalore -","Karnataka 560103","Off Brigade Road","Bangalore - 560103","Ulsoo","Bengalore","Bengaluru"],"Bangalore",inplace=True)

dataset["CITY"].replace(["Thane West","Kalyan West","Thane (W)"],"Thane",inplace=True)

foodtest["CITY"].replace(["Thane West","Kalyan West","Thane (W)"],"Thane",inplace=True)

dataset["CITY"].replace(["Chennai Teynampet","Kilpauk","Dewan Rama Road","Avadi","Velachery","Chennai 600034.","chennai","Tamil Nadu","Chennai - 34 Landmark - Near Loyola College","Chenn ai","Potheri","Anna Salai","Anna Nagar East","Chennai Padur","Mogappair. Chennai","Chennai Opposite 5C Bus stand","Chennai Thousand Lights","Chennai Chrompet","Chennai-40","OMR Karapakkam","Nallathambi Main Road","ECR NEELANKARAI Chennai 600115","Chennai Perungudi","Chennai."],"Chennai",inplace=True)

foodtest["CITY"].replace(["Chennai Teynampet","Kilpauk","Dewan Rama Road","Avadi","Velachery","Chennai 600034.","chennai","Tamil Nadu","Chennai - 34 Landmark - Near Loyola College","Chenn ai","Potheri","Anna Salai","Anna Nagar East","Chennai Padur","Mogappair. Chennai","Chennai Opposite 5C Bus stand","Chennai Thousand Lights","Chennai Chrompet","Chennai-40","OMR Karapakkam","Nallathambi Main Road","ECR NEELANKARAI Chennai 600115","Chennai Perungudi","Chennai."],"Chennai",inplace=True)

dataset["CITY"].replace(["Secunderabad main road near signal NMREC COLLEGE"],"Secunderabad",inplace=True)

foodtest["CITY"].replace(["Secunderabad main road near signal NMREC COLLEGE"],"Secunderabad",inplace=True)

dataset["CITY"].replace(["opp gurudwara Shakurour","Delhi","New Delhi 110075","Delhi 110085","PVR plaza cinema building Connaught Place","Dist. Center New Delhi","Chander Nagar New Delhi","Delhi NCR"],"New Delhi",inplace=True)

foodtest["CITY"].replace(["opp gurudwara Shakurour","Delhi","New Delhi 110075","Delhi 110085","PVR plaza cinema building Connaught Place","Dist. Center New Delhi","Chander Nagar New Delhi","Delhi NCR"],"New Delhi",inplace=True)

dataset["CITY"].replace(["Goregaon West","Gurgaon Haryana India",""],"Gurgaon",inplace=True)

foodtest["CITY"].replace(["Goregaon West","Gurgaon Haryana India",""],"Gurgaon",inplace=True)

dataset["CITY"].replace(["Near Sector 110 Noida","Uttar Pradesh"],"Noida",inplace=True)

foodtest["CITY"].replace(["Near Sector 110 Noida","Uttar Pradesh"],"Noida",inplace=True)

dataset=pd.concat([dataset,pd.get_dummies(dataset["CITY"])],axis=1)

foodtest=pd.concat([foodtest,pd.get_dummies(foodtest["CITY"])],axis=1)

BarFood=list(dataset["CUISINES"])
for i in range(len(BarFood)):
    if "Bar Food" in BarFood[i]:
        BarFood[i]=1
    elif "Bar Food" not in BarFood[i]:
        BarFood[i]=0
dataset["BarFood"]=BarFood

BarFood=list(foodtest["CUISINES"])
for i in range(len(BarFood)):
    if "Bar Food" in BarFood[i]:
        BarFood[i]=1
    elif "Bar Food" not in BarFood[i]:
        BarFood[i]=0
foodtest["BarFood"]=BarFood

FingerFood=list(dataset["CUISINES"])
for i in range(len(FingerFood)):
    if "Finger Food" in FingerFood[i]:
        FingerFood[i]=1
    elif "Finger Food" not in FingerFood[i]:
        FingerFood[i]=0
dataset["FingerFood"]=FingerFood

FingerFood=list(foodtest["CUISINES"])
for i in range(len(FingerFood)):
    if "Finger Food" in FingerFood[i]:
        FingerFood[i]=1
    elif "Finger Food" not in FingerFood[i]:
        FingerFood[i]=0
foodtest["FingerFood"]=FingerFood

Japanese=list(dataset["CUISINES"])
for i in range(len(Japanese)):
    if "Japanese" in Japanese[i]:
        Japanese[i]=1
    elif "Japanese" not in Japanese[i]:
        Japanese[i]=0
dataset["Japanese"]=Japanese

Japanese=list(foodtest["CUISINES"])
for i in range(len(Japanese)):
    if "Japanese" in Japanese[i]:
        Japanese[i]=1
    elif "Japanese" not in Japanese[i]:
        Japanese[i]=0
foodtest["Japanese"]=Japanese

Mithai=list(dataset["CUISINES"])
for i in range(len(Mithai)):
    if "Mithai" in Mithai[i]:
        Mithai[i]=1
    elif "Mithai" not in Mithai[i]:
        Mithai[i]=0
dataset["Mithai"]=Mithai

Mithai=list(foodtest["CUISINES"])
for i in range(len(Mithai)):
    if "Mithai" in Mithai[i]:
        Mithai[i]=1
    elif "Mithai" not in Mithai[i]:
        Mithai[i]=0
foodtest["Mithai"]=Mithai

Oriya=list(dataset["CUISINES"])
for i in range(len(Oriya)):
    if "Oriya" in Oriya[i]:
        Oriya[i]=1
    elif "Oriya" not in Oriya[i]:
        Oriya[i]=0
dataset["Oriya"]=Oriya

Oriya=list(foodtest["CUISINES"])
for i in range(len(Oriya)):
    if "Oriya" in Oriya[i]:
        Oriya[i]=1
    elif "Oriya" not in Oriya[i]:
        Oriya[i]=0
foodtest["Oriya"]=Oriya

Indian=list(dataset["CUISINES"])
for i in range(len(Indian)):
    if "Indian  " in Indian[i]:
        Indian[i]=1
    elif "Indian  " not in Indian[i]:
        Indian[i]=0
dataset["Indian"]=Indian

Indian=list(foodtest["CUISINES"])
for i in range(len(Indian)):
    if "Indian  " in Indian[i]:
        Indian[i]=1
    elif "Indian  " not in Indian[i]:
        Indian[i]=0
foodtest["Indian"]=Indian

Juices=list(dataset["CUISINES"])
for i in range(len(Juices)):
    if "Juices" in Juices[i]:
        Juices[i]=1
    elif "Juices" not in Juices[i]:
        Juices[i]=0
dataset["Juices"]=Juices

Juices=list(foodtest["CUISINES"])
for i in range(len(Juices)):
    if "Juices" in Juices[i]:
        Juices[i]=1
    elif "Juices" not in Juices[i]:
        Juices[i]=0
foodtest["Juices"]=Juices

dataset.drop(dataset.columns[[0,1,2,3,4,5,6,7,8]],axis=1,inplace=True)

t["COST"]=t.COST.astype(float)

dataset["Happiness"]=dataset.Happiness.astype(float)

foodtest["Happiness"]=foodtest.Happiness.astype(float)

foodtest.drop(foodtest.columns[[0,1,2,3,4,5,6,7,8]],axis=1,inplace=True)

train= dataset.iloc[0:train_objs_num]

train.fillna(0, inplace=True)

train_train,train_test,t_train,t_test= train_test_split(train,t,test_size=0.2,random_state=1)

params = {'min_child_weight':[4,5], 'gamma':[i/10.0 for i in range(3,6)],  'subsample':[i/10.0 for i in range(6,11)],
'colsample_bytree':[i/10.0 for i in range(6,11)], 'max_depth': [2,3,4]}

xgb = XGBRegressor(nthread=-1)

grid = GridSearchCV(xgb, params)

grid.fit(train_train,t_train)

Y_pred=grid.best_estimator_.predict(train_test)

from sklearn import metrics

print('Mean Absolute Error:', metrics.mean_absolute_error(t_test, Y_pred))  
print('Mean Squared Error:', metrics.mean_squared_error(t_test, Y_pred))  
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(t_test, Y_pred)))


